{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11908588,"sourceType":"datasetVersion","datasetId":7486370}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM\n\nmodel_name = \"UBC-NLP/AraT5v2-base-1024\"\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n\nnum_params = sum(p.numel() for p in model.parameters())\nprint(f\"Nombre total de param√®tres : {num_params / 1e6:.2f} millions\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-22T18:07:38.007243Z","iopub.execute_input":"2025-05-22T18:07:38.007566Z","iopub.status.idle":"2025-05-22T18:08:24.278890Z","shell.execute_reply.started":"2025-05-22T18:07:38.007534Z","shell.execute_reply":"2025-05-22T18:08:24.277460Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/699 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39270be47ff44bbc907ca104ce798d8c"}},"metadata":{}},{"name":"stderr","text":"2025-05-22 18:07:57.655742: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747937277.915094      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747937277.997679      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5e05324565249f885e6383a7e18f219"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"771bc05a9757455c9d61fecd98e181f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da4babcf850446b48b9003823c396eb2"}},"metadata":{}},{"name":"stdout","text":"Nombre total de param√®tres : 367.51 millions\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_parquet(\"/kaggle/input/data-set-full\")\n\n# Affiche les premi√®res lignes pour v√©rifier\nprint(df.head())\n\nfrom datasets import Dataset\n\ndataset = Dataset.from_pandas(df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T18:08:36.808351Z","iopub.execute_input":"2025-05-22T18:08:36.808690Z","iopub.status.idle":"2025-05-22T18:08:49.605772Z","shell.execute_reply.started":"2025-05-22T18:08:36.808662Z","shell.execute_reply":"2025-05-22T18:08:49.604759Z"}},"outputs":[{"name":"stdout","text":"  index                                            summary  \\\n0     1  ÿ®ÿØÿ£ÿ™ ŸÖÿ≠ŸÉŸÖÿ© ŸÖŸäŸàŸÜÿÆ ÿßŸÑŸÜÿ∏ÿ± ŸÅŸä ÿßÿ™ŸáÿßŸÖÿßÿ™ ŸÖÿ™ÿπŸÑŸÇÿ© ÿ®ÿ±ÿ¨ŸÑ ...   \n1     2  ÿ£ÿπŸÑŸÜ ÿ≠ÿßŸÉŸÖ ŸÉÿßÿ±ŸàŸÑÿßŸäŸÜÿß ÿßŸÑÿ¥ŸÖÿßŸÑŸäÿ© ÿ≠ÿßŸÑÿ© ÿßŸÑÿ∑Ÿàÿ±ÿßÿ¶ ŸÅŸä ŸÖ...   \n2     3  ŸÇÿßŸÑÿ™ Ÿàÿ≤ÿßÿ±ÿ© ÿßŸÑÿØŸÅÿßÿπ ÿßŸÑÿ£ŸÖÿ±ŸäŸÉŸäÿ© (ÿßŸÑÿ®ŸÜÿ™ÿßÿ∫ŸàŸÜ) ÿ•ŸÜ ÿØÿßÿπ...   \n3     4  \"ŸÅÿ¥ŸÑÿ™ ÿßŸÑŸàŸÑÿßŸäÿßÿ™ ÿßŸÑŸÖÿ™ÿ≠ÿØÿ© Ÿàÿ±Ÿàÿ≥Ÿäÿß ŸÅŸä ÿßŸÑÿßÿ™ŸÅÿßŸÇ ÿπŸÑŸâ ŸÉ...   \n4     5  ÿ£ÿ´ŸÜŸâ ŸÖÿØÿ±ÿ® ÿ®ÿßŸäÿ±ŸÜ ŸÖŸäŸàŸÜŸäÿÆ ŸÉÿßÿ±ŸÑŸà ÿ£ŸÜÿ¥ŸäŸÑŸàÿ™Ÿä ÿπŸÑŸâ ŸÖÿ≥ÿßÿπ...   \n\n                                             article  text_length  \\\n0  \"ÿ®ÿØÿ£ÿ™ ÿßŸÑŸäŸàŸÖ ÿßŸÑÿ¨ŸÖÿπÿ©( 23 ÿ£ŸäŸÑŸàŸÑ/ ÿ≥ÿ®ÿ™ŸÖÿ®ÿ± 2016 ) ŸÅŸä...          318   \n1  \"ŸÇÿßŸÑ ŸÖÿ≥ÿ§ŸàŸÑŸàŸÜ ÿ•ŸÜ ÿ¥ÿÆÿµÿß ÿ£ÿµŸäÿ® ÿ•ÿµÿßÿ®ÿ© ÿ®ÿßŸÑÿ∫ÿ© ÿ®ÿπÿØ ÿ™ÿπÿ±ÿ∂...          379   \n2  \"ÿ£ÿπŸÑŸÜ ŸÖÿ≥ÿ§ŸàŸÑ ŸÅŸä ÿßŸÑÿ®ŸÜÿ™ÿßÿ∫ŸàŸÜ ÿ£ŸÜ ÿ¨ŸÜŸàÿØÿß ÿ£ŸÖÿ±ŸäŸÉŸäŸäŸÜ ŸÅŸä ...          201   \n3  \"ÿßÿ¨ÿ™ŸÖÿπÿ™ ÿßŸÑŸÖÿ¨ŸÖŸàÿπÿ© ÿßŸÑÿØŸàŸÑŸäÿ© ŸÑÿØÿπŸÖ ÿ≥Ÿàÿ±Ÿäÿß ÿπŸÑŸâ ŸáÿßŸÖÿ¥ ÿß...          194   \n4  \"ŸÇÿßŸÑ ÿßŸÑÿ•Ÿäÿ∑ÿßŸÑŸä ŸÉÿßÿ±ŸÑŸà ÿ£ŸÜÿ¥ŸäŸÑŸàÿ™Ÿä ÿßŸÑŸÖÿØŸäÿ± ÿßŸÑŸÅŸÜŸä ŸÑŸÅÿ±Ÿä...          183   \n\n   summary_length  diff diff_category  \\\n0              37   281      ŸÅÿ±ŸÇ ŸÉÿ®Ÿäÿ±   \n1              33   346      ŸÅÿ±ŸÇ ŸÉÿ®Ÿäÿ±   \n2              35   166      ŸÅÿ±ŸÇ ŸÉÿ®Ÿäÿ±   \n3              28   166      ŸÅÿ±ŸÇ ŸÉÿ®Ÿäÿ±   \n4              29   154      ŸÅÿ±ŸÇ ŸÉÿ®Ÿäÿ±   \n\n                                          text_clean  \\\n0  ÿ®ÿØÿßÿ™ ÿßŸÑŸäŸàŸÖ ÿßŸÑÿ¨ŸÖÿπŸá 23 ÿßŸäŸÑŸàŸÑ ÿ≥ÿ®ÿ™ŸÖÿ®ÿ± 2016 ŸÅŸä ŸÖŸäŸàŸÜ...   \n1  ŸÇÿßŸÑ ŸÖÿ≥ÿ§ŸàŸÑŸàŸÜ ÿßŸÜ ÿ¥ÿÆÿµÿß ÿßÿµŸäÿ® ÿßÿµÿßÿ®Ÿá ÿ®ÿßŸÑÿ∫Ÿá ÿ®ÿπÿØ ÿ™ÿπÿ±ÿ∂Ÿá...   \n2  ÿßÿπŸÑŸÜ ŸÖÿ≥ÿ§ŸàŸÑ ŸÅŸä ÿßŸÑÿ®ŸÜÿ™ÿßÿ∫ŸàŸÜ ÿßŸÜ ÿ¨ŸÜŸàÿØÿß ÿßŸÖÿ±ŸäŸÉŸäŸäŸÜ ŸÅŸä ÿ¥...   \n3  ÿßÿ¨ÿ™ŸÖÿπÿ™ ÿßŸÑŸÖÿ¨ŸÖŸàÿπŸá ÿßŸÑÿØŸàŸÑŸäŸá ŸÑÿØÿπŸÖ ÿ≥Ÿàÿ±Ÿäÿß ÿπŸÑŸâ ŸáÿßŸÖÿ¥ ÿßÿ¨...   \n4  ŸÇÿßŸÑ ÿßŸÑÿßŸäÿ∑ÿßŸÑŸä ŸÉÿßÿ±ŸÑŸà ÿßŸÜÿ¥ŸäŸÑŸàÿ™Ÿä ÿßŸÑŸÖÿØŸäÿ± ÿßŸÑŸÅŸÜŸä ŸÑŸÅÿ±ŸäŸÇ...   \n\n                                       summary_clean  \n0  ÿ®ÿØÿßÿ™ ŸÖÿ≠ŸÉŸÖŸá ŸÖŸäŸàŸÜÿÆ ÿßŸÑŸÜÿ∏ÿ± ŸÅŸä ÿßÿ™ŸáÿßŸÖÿßÿ™ ŸÖÿ™ÿπŸÑŸÇŸá ÿ®ÿ±ÿ¨ŸÑ ...  \n1  ÿßÿπŸÑŸÜ ÿ≠ÿßŸÉŸÖ ŸÉÿßÿ±ŸàŸÑÿßŸäŸÜÿß ÿßŸÑÿ¥ŸÖÿßŸÑŸäŸá ÿ≠ÿßŸÑŸá ÿßŸÑÿ∑Ÿàÿ±ÿßÿ¶ ŸÅŸä ŸÖ...  \n2  ŸÇÿßŸÑÿ™ Ÿàÿ≤ÿßÿ±Ÿá ÿßŸÑÿØŸÅÿßÿπ ÿßŸÑÿßŸÖÿ±ŸäŸÉŸäŸá ÿßŸÑÿ®ŸÜÿ™ÿßÿ∫ŸàŸÜ ÿßŸÜ ÿØÿßÿπÿ¥ ...  \n3  ŸÅÿ¥ŸÑÿ™ ÿßŸÑŸàŸÑÿßŸäÿßÿ™ ÿßŸÑŸÖÿ™ÿ≠ÿØŸá Ÿàÿ±Ÿàÿ≥Ÿäÿß ŸÅŸä ÿßŸÑÿßÿ™ŸÅÿßŸÇ ÿπŸÑŸâ ŸÉŸä...  \n4  ÿßÿ´ŸÜŸâ ŸÖÿØÿ±ÿ® ÿ®ÿßŸäÿ±ŸÜ ŸÖŸäŸàŸÜŸäÿÆ ŸÉÿßÿ±ŸÑŸà ÿßŸÜÿ¥ŸäŸÑŸàÿ™Ÿä ÿπŸÑŸâ ŸÖÿ≥ÿßÿπ...  \n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_name = \"UBC-NLP/AraT5v2-base-1024\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nmax_input_length = 512   # ou la longueur max de ton texte\nmax_target_length = 128  # ou la longueur max de ton r√©sum√©\n\ndef preprocess_function(examples):\n    inputs = examples[\"text_clean\"]\n    targets = examples[\"summary\"]\n\n    # Tokenize inputs\n    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, padding=\"max_length\")\n\n    # Tokenize targets\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(targets, max_length=max_target_length, truncation=True, padding=\"max_length\")\n\n    labels_ids = labels[\"input_ids\"]\n    # Remplacer les pads par -100 pour ignorer la perte sur ces tokens\n    labels_ids = [\n        [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels_ids\n    ]\n\n    model_inputs[\"labels\"] = labels_ids\n    return model_inputs\n\ntokenized_dataset = dataset.map(preprocess_function, batched=True)\n\n\n ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T18:10:59.554274Z","iopub.execute_input":"2025-05-22T18:10:59.555472Z","iopub.status.idle":"2025-05-22T18:12:36.041668Z","shell.execute_reply.started":"2025-05-22T18:10:59.555435Z","shell.execute_reply":"2025-05-22T18:12:36.040597Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.37k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9893fd1dc196438c993422cb56639d03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/2.35M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44c93ea5122d466c9798a4fba48db358"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/8.40M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06e415a8faa84bafa4e357cab4fa4ed8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27568db33b4c40deb81ec409eff35aeb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/48937 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e44fdc79a0c744bc831dcf41991bef53"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"split_dataset = tokenized_dataset.train_test_split(test_size=0.1, seed=42)\ntrain_dataset = split_dataset[\"train\"]\nval_dataset = split_dataset[\"test\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T18:14:57.064512Z","iopub.execute_input":"2025-05-22T18:14:57.064832Z","iopub.status.idle":"2025-05-22T18:14:57.096964Z","shell.execute_reply.started":"2025-05-22T18:14:57.064810Z","shell.execute_reply":"2025-05-22T18:14:57.095954Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM\n\nmodel_name = \"UBC-NLP/AraT5v2-base-1024\"\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T18:12:41.649672Z","iopub.execute_input":"2025-05-22T18:12:41.649988Z","iopub.status.idle":"2025-05-22T18:12:47.196954Z","shell.execute_reply.started":"2025-05-22T18:12:41.649964Z","shell.execute_reply":"2025-05-22T18:12:47.196169Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"!pip install huggingface_hub transformers datasets\n\nfrom huggingface_hub import notebook_login\nnotebook_login()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T18:12:49.974881Z","iopub.execute_input":"2025-05-22T18:12:49.975859Z","iopub.status.idle":"2025-05-22T18:12:56.116292Z","shell.execute_reply.started":"2025-05-22T18:12:49.975814Z","shell.execute_reply":"2025-05-22T18:12:56.114560Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.31.1)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec>=2023.5.0 (from huggingface_hub)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.4.26)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.9.0.13 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.4.0.6 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.10.19 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.4.40 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.9.5 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.9.41 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fsspec-2025.3.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4af359400055445b80999a0513159a7e"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"!pip install evaluate\n!pip install rouge_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T18:13:25.389106Z","iopub.execute_input":"2025-05-22T18:13:25.389512Z","iopub.status.idle":"2025-05-22T18:13:36.327453Z","shell.execute_reply.started":"2025-05-22T18:13:25.389477Z","shell.execute_reply":"2025-05-22T18:13:36.326261Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.31.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.18)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.0)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rouge_score) (2024.2.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=8c1098535be5c01de9bc1a67014faf2f2004497e7c54b9070df12f1a8ad53ea3\n  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import evaluate\nimport numpy as np\n\nrouge = evaluate.load(\"rouge\")\nbleu = evaluate.load(\"bleu\")  # BLEU classique, utile si tu fais de la traduction ou du r√©sum√© mot √† mot\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T18:13:46.866641Z","iopub.execute_input":"2025-05-22T18:13:46.867011Z","iopub.status.idle":"2025-05-22T18:13:50.244927Z","shell.execute_reply.started":"2025-05-22T18:13:46.866975Z","shell.execute_reply":"2025-05-22T18:13:50.243734Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfda658203514e65aeff85934e9e3d1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"460bac9ff9c14fbba2457a10ed3ba963"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c852b9b89d44417b6b90eac18901224"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ccde441e8df41839688cd5fabd2dbe3"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"def compute_metrics(eval_preds):\n    preds, labels = eval_preds\n    # Supprimer les valeurs -100 dans les labels (elles sont ignor√©es pendant l'entra√Ænement)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n\n    # D√©codage des pr√©dictions et des labels\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # Suppression des espaces superflus\n    decoded_preds = [pred.strip() for pred in decoded_preds]\n    decoded_labels = [label.strip() for label in decoded_labels]\n\n    # Calcul des m√©triques\n    rouge_result = rouge.compute(predictions=decoded_preds, references=decoded_labels)\n    bleu_result = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n\n    # Retourne les scores d'int√©r√™t\n    return {\n        \"rouge1\": rouge_result[\"rouge1\"],\n        \"rouge2\": rouge_result[\"rouge2\"],\n        \"rougeL\": rouge_result[\"rougeL\"],\n        \"bleu\": bleu_result[\"bleu\"],\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T18:13:53.097556Z","iopub.execute_input":"2025-05-22T18:13:53.097895Z","iopub.status.idle":"2025-05-22T18:13:53.104809Z","shell.execute_reply.started":"2025-05-22T18:13:53.097868Z","shell.execute_reply":"2025-05-22T18:13:53.103838Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"!wandb login --relogin 845f8dedf69c8bf78f12b093e8a4ff627911b2e8\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T18:13:56.227443Z","iopub.execute_input":"2025-05-22T18:13:56.227749Z","iopub.status.idle":"2025-05-22T18:14:03.416937Z","shell.execute_reply.started":"2025-05-22T18:13:56.227727Z","shell.execute_reply":"2025-05-22T18:14:03.415479Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import wandb\nwandb.init(\n    project=\"arabic-summarization\",  # Choisis un nom de projet\n    name=\"arabart-run-last\"             # Nom du run (facultatif)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T18:14:10.227573Z","iopub.execute_input":"2025-05-22T18:14:10.228315Z","iopub.status.idle":"2025-05-22T18:14:25.153741Z","shell.execute_reply.started":"2025-05-22T18:14:10.228275Z","shell.execute_reply":"2025-05-22T18:14:25.152596Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmohamedmourinou2018\u001b[0m (\u001b[33mmohamedmourinou2018-ensa-al-hoceima\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250522_181418-myhjssej</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/mohamedmourinou2018-ensa-al-hoceima/arabic-summarization/runs/myhjssej' target=\"_blank\">arabart-run-last</a></strong> to <a href='https://wandb.ai/mohamedmourinou2018-ensa-al-hoceima/arabic-summarization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/mohamedmourinou2018-ensa-al-hoceima/arabic-summarization' target=\"_blank\">https://wandb.ai/mohamedmourinou2018-ensa-al-hoceima/arabic-summarization</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/mohamedmourinou2018-ensa-al-hoceima/arabic-summarization/runs/myhjssej' target=\"_blank\">https://wandb.ai/mohamedmourinou2018-ensa-al-hoceima/arabic-summarization/runs/myhjssej</a>"},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/mohamedmourinou2018-ensa-al-hoceima/arabic-summarization/runs/myhjssej?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7a1ed51eb050>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"max_train_size = 20000\n\n# Prendre seulement les 20k premiers exemples dans train\ntrain_dataset = split_dataset[\"train\"].select(range(min(len(split_dataset[\"train\"]), max_train_size)))\n\n# Pour la validation, tu peux garder tout ou aussi limiter si tu veux\nval_dataset = split_dataset[\"test\"]  # ou limiter aussi si besoin\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T18:15:08.298547Z","iopub.execute_input":"2025-05-22T18:15:08.298859Z","iopub.status.idle":"2025-05-22T18:15:08.310075Z","shell.execute_reply.started":"2025-05-22T18:15:08.298833Z","shell.execute_reply":"2025-05-22T18:15:08.309237Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./results\",\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    eval_strategy=\"epoch\",\n    save_strategy=\"steps\",\n    save_steps=500,\n    learning_rate=1e-5,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    predict_with_generate=True,\n    logging_dir=\"./logs\",\n    max_steps=1000,\n    logging_steps=10,\n    fp16=True,\n    push_to_hub=True,                # <-- Active le push automatique\n    hub_model_id=\"mohamedmou/arabic-summarizer\",  \n    report_to=\"wandb\",  # important !\n# <-- Nom du repo HuggingFace Hub\n# si tu as une GPU compatible\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,  # üî• Ajout ici\n\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T18:20:03.969272Z","iopub.execute_input":"2025-05-22T18:20:03.969687Z","iopub.status.idle":"2025-05-22T18:20:04.143489Z","shell.execute_reply.started":"2025-05-22T18:20:03.969658Z","shell.execute_reply":"2025-05-22T18:20:04.142344Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/2417636065.py:25: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"trainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T18:20:07.486170Z","iopub.execute_input":"2025-05-22T18:20:07.487405Z","iopub.status.idle":"2025-05-22T21:33:36.089497Z","shell.execute_reply.started":"2025-05-22T18:20:07.487288Z","shell.execute_reply":"2025-05-22T21:33:36.086285Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='516' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 516/1000 3:12:42 < 3:01:27, 0.04 it/s, Epoch 0.10/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/49973641.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2234\u001b[0m                 \u001b[0;31m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2236\u001b[0;31m                 return inner_training_loop(\n\u001b[0m\u001b[1;32m   2237\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2238\u001b[0m                     \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2609\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_pre_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2611\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2613\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accelerate_step_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mDistributedType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXLA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_xla_gradients_synced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                     \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opt_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_by_lr_sched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m                             )\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    241\u001b[0m             )\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             adamw(\n\u001b[0m\u001b[1;32m    244\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adamw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    876\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;31m# Lastly, switch back to complex view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":21},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n\ncheckpoint_path = \"/kaggle/working/results/checkpoint-500\"\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(checkpoint_path)\ntokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n\nmodel.push_to_hub(\"mohamedmou/arabic-summarizer\", commit_message=\"Push checkpoint 500\")\ntokenizer.push_to_hub(\"mohamedmou/arabic-summarizer\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T21:34:05.872761Z","iopub.execute_input":"2025-05-22T21:34:05.873410Z","iopub.status.idle":"2025-05-22T21:34:23.121396Z","shell.execute_reply.started":"2025-05-22T21:34:05.873316Z","shell.execute_reply":"2025-05-22T21:34:23.120280Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b36df717cbae406f9b95e867451daae8"}},"metadata":{}},{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/mohamedmou/arabic-summarizer/commit/235eb247c4bd6b59916e6d4f3e7853b92f1d86d8', commit_message='Upload tokenizer', commit_description='', oid='235eb247c4bd6b59916e6d4f3e7853b92f1d86d8', pr_url=None, repo_url=RepoUrl('https://huggingface.co/mohamedmou/arabic-summarizer', endpoint='https://huggingface.co', repo_type='model', repo_id='mohamedmou/arabic-summarizer'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n# Nom du mod√®le Hugging Face\nmodel_name = \"mohamedmou/arabic-summarizer\"\n\n# Charger le tokenizer et le mod√®le depuis Hugging Face Hub\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n\n# Exemple de texte arabe √† r√©sumer\ntext = \"\"\"\n\"ÿ™ÿ¥ŸáÿØ ŸÖŸÜÿ∑ŸÇÿ© ÿßŸÑÿ¥ÿ±ŸÇ ÿßŸÑÿ£Ÿàÿ≥ÿ∑ Ÿàÿ¥ŸÖÿßŸÑ ÿ£ŸÅÿ±ŸäŸÇŸäÿß ÿ™ÿ≠ÿØŸäÿßÿ™ ÿßŸÇÿ™ÿµÿßÿØŸäÿ© Ÿàÿ≥Ÿäÿßÿ≥Ÿäÿ© ŸÉÿ®Ÿäÿ±ÿ© ÿ®ÿ≥ÿ®ÿ® ÿßŸÑÿµÿ±ÿßÿπÿßÿ™ ÿßŸÑŸÖÿ≥ÿ™ŸÖÿ±ÿ© ŸàÿßŸÑÿ™ÿ∫Ÿäÿ±ÿßÿ™ ÿßŸÑÿ¨ŸäŸàÿ≥Ÿäÿßÿ≥Ÿäÿ© ŸÅŸä ÿßŸÑŸÖŸÜÿ∑ŸÇÿ©. ÿ±ÿ∫ŸÖ ÿ∞ŸÑŸÉÿå ÿ™ÿ®ÿ±ÿ≤ ŸÅÿ±ÿµ ŸÑŸÑŸÜŸÖŸà ÿßŸÑÿßŸÇÿ™ÿµÿßÿØŸä ŸÖŸÜ ÿÆŸÑÿßŸÑ ÿ™ÿ∑ŸàŸäÿ± ŸÇÿ∑ÿßÿπÿßÿ™ ÿ¨ÿØŸäÿØÿ© ŸÖÿ´ŸÑ ÿßŸÑÿ™ŸÉŸÜŸàŸÑŸàÿ¨Ÿäÿß ŸàÿßŸÑÿ∑ÿßŸÇÿ© ÿßŸÑŸÖÿ™ÿ¨ÿØÿØÿ©. ÿßŸÑÿ≠ŸÉŸàŸÖÿßÿ™ ŸÅŸä ÿ®ÿπÿ∂ ÿßŸÑÿØŸàŸÑ ÿ™ÿ≥ÿπŸâ ÿ•ŸÑŸâ ÿ™ÿπÿ≤Ÿäÿ≤ ÿßŸÑÿßÿ≥ÿ™ŸÇÿ±ÿßÿ± Ÿàÿ™ÿ≠ÿ≥ŸäŸÜ ÿßŸÑÿ®ŸÜŸäÿ© ÿßŸÑÿ™ÿ≠ÿ™Ÿäÿ© ŸÑÿØÿπŸÖ ÿßŸÑÿ™ŸÜŸÖŸäÿ© ÿßŸÑŸÖÿ≥ÿ™ÿØÿßŸÖÿ©. ŸÉŸÖÿß ÿ£ŸÜ ÿßŸÑÿßÿ≥ÿ™ÿ´ŸÖÿßÿ± ŸÅŸä ÿßŸÑÿ™ÿπŸÑŸäŸÖ ŸàÿßŸÑÿ¥ÿ®ÿßÿ® ŸäÿπÿØ ŸÖŸÅÿ™ÿßÿ≠ÿßŸã ŸÑŸÖÿ≥ÿ™ŸÇÿ®ŸÑ ÿ£ŸÅÿ∂ŸÑ. ŸàŸÖÿπ ÿ∞ŸÑŸÉÿå ŸÑÿß ÿ™ÿ≤ÿßŸÑ ÿßŸÑÿ™ÿ≠ÿØŸäÿßÿ™ ÿßŸÑÿ£ŸÖŸÜŸäÿ© ŸàÿßŸÑÿßÿ¨ÿ™ŸÖÿßÿπŸäÿ© ÿ™ÿ¥ŸÉŸÑ ÿπÿßÿ¶ŸÇÿßŸã ÿ£ŸÖÿßŸÖ ÿ™ÿ≠ŸÇŸäŸÇ Ÿáÿ∞Ÿá ÿßŸÑÿ£ŸáÿØÿßŸÅÿå ŸÖŸÖÿß Ÿäÿ™ÿ∑ŸÑÿ® ÿ™ÿπÿßŸàŸÜÿßŸã ÿ•ŸÇŸÑŸäŸÖŸäÿßŸã ŸàÿØŸàŸÑŸäÿßŸã ŸÖŸÉÿ´ŸÅÿßŸã ŸÑŸÑÿ™ÿ∫ŸÑÿ® ÿπŸÑŸäŸáÿß.\"\n\n\n\n\"\"\"\n\n# Tokenizer le texte, limiter la longueur max √† 524 tokens (ajuste selon ton mod√®le)\ninputs = tokenizer(text, return_tensors=\"pt\", max_length=524, truncation=True)\n\n# G√©n√©rer un r√©sum√© avec beam search (4 faisceaux), limiter √† 100 tokens max\nsummary_ids = model.generate(\n    inputs[\"input_ids\"],\n    max_length=100,\n    num_beams=4,\n    early_stopping=True\n)\n\n# D√©coder la sortie en texte lisible (sans tokens sp√©ciaux)\nsummary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n\nprint(\"R√©sum√© g√©n√©r√© :\", summary)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T21:49:10.284973Z","iopub.execute_input":"2025-05-22T21:49:10.285468Z","iopub.status.idle":"2025-05-22T21:49:15.894046Z","shell.execute_reply.started":"2025-05-22T21:49:10.285434Z","shell.execute_reply":"2025-05-22T21:49:15.892675Z"}},"outputs":[{"name":"stdout","text":"R√©sum√© g√©n√©r√© : ÿ™ÿ¥ŸáÿØ ŸÖŸÜÿ∑ŸÇÿ© ÿßŸÑÿ¥ÿ±ŸÇ ÿßŸÑÿ£Ÿàÿ≥ÿ∑ Ÿàÿ¥ŸÖÿßŸÑ ÿ£ŸÅÿ±ŸäŸÇŸäÿß ÿ™ÿ≠ÿØŸäÿßÿ™ ÿßŸÇÿ™ÿµÿßÿØŸäÿ© Ÿàÿ≥Ÿäÿßÿ≥Ÿäÿ© ŸÉÿ®Ÿäÿ±ÿ© ÿ®ÿ≥ÿ®ÿ® ÿßŸÑÿµÿ±ÿßÿπÿßÿ™ ÿßŸÑŸÖÿ≥ÿ™ŸÖÿ±ÿ© ŸàÿßŸÑÿ™ÿ∫Ÿäÿ±ÿßÿ™ ÿßŸÑÿ¨ŸäŸàÿ≥Ÿäÿßÿ≥Ÿäÿ©. ŸàŸÖÿπ ÿ∞ŸÑŸÉÿå ÿ™ÿ®ÿ±ÿ≤ ŸÅÿ±ÿµ ŸÑŸÑŸÜŸÖŸà ÿßŸÑÿßŸÇÿ™ÿµÿßÿØŸä ŸÖŸÜ ÿÆŸÑÿßŸÑ ÿ™ÿ∑ŸàŸäÿ± ŸÇÿ∑ÿßÿπÿßÿ™ ÿ¨ÿØŸäÿØÿ© ŸÖÿ´ŸÑ ÿßŸÑÿ™ŸÉŸÜŸàŸÑŸàÿ¨Ÿäÿß ŸàÿßŸÑÿ∑ÿßŸÇÿ© ÿßŸÑŸÖÿ™ÿ¨ÿØÿØÿ©.\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"!pip install gradio\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T21:51:00.871187Z","iopub.execute_input":"2025-05-22T21:51:00.871989Z","iopub.status.idle":"2025-05-22T21:51:13.446644Z","shell.execute_reply.started":"2025-05-22T21:51:00.871950Z","shell.execute_reply":"2025-05-22T21:51:13.445447Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting gradio\n  Downloading gradio-5.31.0-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\nCollecting fastapi<1.0,>=0.115.2 (from gradio)\n  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\nCollecting ffmpy (from gradio)\n  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\nCollecting gradio-client==1.10.1 (from gradio)\n  Downloading gradio_client-1.10.1-py3-none-any.whl.metadata (7.1 kB)\nCollecting groovy~=0.1 (from gradio)\n  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\nRequirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.1)\nRequirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\nRequirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\nRequirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\nRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (25.0)\nRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.3)\nRequirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\nRequirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\nRequirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\nCollecting python-multipart>=0.0.18 (from gradio)\n  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\nCollecting ruff>=0.9.3 (from gradio)\n  Downloading ruff-0.11.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\nCollecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\nCollecting semantic-version~=2.0 (from gradio)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting starlette<1.0,>=0.40.0 (from gradio)\n  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\nCollecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\nRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\nCollecting uvicorn>=0.14.0 (from gradio)\n  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.0)\nRequirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.0->gradio) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.0->gradio) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\nDownloading gradio-5.31.0-py3-none-any.whl (54.2 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.2/54.2 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio_client-1.10.1-py3-none-any.whl (323 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m323.1/323.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\nDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\nDownloading ruff-0.11.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\nDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\nDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\nInstalling collected packages: uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, starlette, safehttpx, gradio-client, fastapi, gradio\nSuccessfully installed fastapi-0.115.12 ffmpy-0.5.0 gradio-5.31.0 gradio-client-1.10.1 groovy-0.1.2 python-multipart-0.0.20 ruff-0.11.11 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"import gradio as gr\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\nmodel_name = \"mohamedmou/arabic-summarizer\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n\ndef summarize(text):\n    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True)\n    summary_ids = model.generate(inputs[\"input_ids\"], max_length=150, num_beams=4, early_stopping=True)\n    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n    return summary\n\niface = gr.Interface(\n    fn=summarize,\n    inputs=gr.Textbox(lines=10, placeholder=\"Ins√©rez ici un texte arabe √† r√©sumer...\", label=\"Texte √† r√©sumer\"),\n    outputs=gr.Textbox(lines=5, label=\"R√©sum√© g√©n√©r√©\"),\n    title=\"R√©sum√© automatique - Arabe\",\n    description=\"Entrez un texte en arabe pour g√©n√©rer un r√©sum√© automatique.\"\n)\n\niface.launch()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T21:51:22.270852Z","iopub.execute_input":"2025-05-22T21:51:22.271219Z","iopub.status.idle":"2025-05-22T21:51:29.756913Z","shell.execute_reply.started":"2025-05-22T21:51:22.271186Z","shell.execute_reply":"2025-05-22T21:51:29.755939Z"}},"outputs":[{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7860\nIt looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n\n* Running on public URL: https://48eadfacdb89fe2419.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://48eadfacdb89fe2419.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}